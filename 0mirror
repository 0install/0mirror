#!/usr/bin/env python
# Copyright (C) 2007, Thomas Leonard
# See the COPYING file for details, or visit http://0install.net.

from optparse import OptionParser
import os, sys, time, shutil, subprocess, signal
from logging import info, debug, warn
from xml.dom import minidom

signal.alarm(10 * 60)		# Abort after 10 minutes

from zeroinstall import SafeException
from zeroinstall.injector.iface_cache import iface_cache
from zeroinstall.injector import basedir, model, namespaces, policy, handler, gpg

from atom import AtomFeed, set_element

# Site configuration!
site_address = "http://roscidus.com/0mirror"

version = '0.1'

parser = OptionParser(usage="usage: %prog [options] PUBLIC-DIR")
parser.add_option("-v", "--verbose", help="more verbose output", action='count')
parser.add_option("-V", "--version", help="display version information", action='store_true')

(options, args) = parser.parse_args()

if options.version:
	print "0mirror (zero-install) " + version
	print "Copyright (C) 2007 Thomas Leonard"
	print "This program comes with ABSOLUTELY NO WARRANTY,"
	print "to the extent permitted by law."
	print "You may redistribute copies of this program"
	print "under the terms of the GNU General Public License."
	print "For more information about these matters, see the file named COPYING."
	sys.exit(0)

if options.verbose:
	import logging
	logger = logging.getLogger()
	if options.verbose == 1:
		logger.setLevel(logging.INFO)
	else:
		logger.setLevel(logging.DEBUG)

if len(args) != 1:
	parser.print_help()
	sys.exit(1)
public_dir = args[0]

feed_file = os.path.join(public_dir, 'feed-list')

def escape_slashes(path):
	return path.replace('/', '#')

def ensure_dirs(path):
	if not os.path.isdir(path):
		os.makedirs(path)

summary_xml = """
<summary type='xhtml'>
  <div xmlns="http://www.w3.org/1999/xhtml">
    <a href=""/> - <span/>
  </div>
</summary>
"""

key_dir = os.path.join(public_dir, 'keys')
ensure_dirs(key_dir)
keys = set()
def ensure_key(fingerprint):
	if fingerprint in keys:
		return
	key_path = os.path.join(key_dir, fingerprint[-16:] + '.gpg')
	child = subprocess.Popen(['gpg', '-a', '--export', fingerprint], stdout = subprocess.PIPE)
	keydata, unused = child.communicate()
	stream = file(key_path, 'w')
	stream.write(keydata)
	stream.close()
	print "Exported key", fingerprint
	keys.add(fingerprint)

ifaces = []

def format_date(date):
	return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(date))

def get_feed_dir(feed):
	if '#' in feed:
		raise SafeException("Invalid URL '%s'" % feed)
	scheme, rest = feed.split('://', 1)
	domain, rest = rest.split('/', 1)
	assert scheme in ('http', 'https', 'ftp')	# Just to check for mal-formed lines; add more as needed
	for x in [scheme, domain, rest]:
		if not x or x.startswith(','):
			raise SafeException("Invalid URL '%s'" % feed)
	return os.path.join('feeds', scheme, domain, escape_slashes(rest))

now = format_date(time.time())
news_feed = AtomFeed(title = "Zero Install News Feed",
			link = site_address + "/news-feed.xml",
			updated = now,
			author = "0mirror")

try:
	if not os.path.isdir(public_dir):
		raise SafeException("Public directory '%s' does not exist. "
				    "To setup a new site, create it as an empty directory now." % public_dir)
	if not os.path.isfile(feed_file):
		raise SafeException("File '%s' does not exist. It should contain a list of feed URLs, one per line" % feed_file)
	print "Reading", feed_file
	feeds = filter(None, file(feed_file).read().split('\n'))
	handler = handler.Handler()
	for feed in feeds:
		info("Processing feed '%s'", feed)
		feed_dir = os.path.join(public_dir, get_feed_dir(feed))
		ensure_dirs(feed_dir)

		#print "Updating", feed
		p = policy.Policy(feed, handler)
		p.stale_feeds = set()
		iface = p.get_interface(feed)	# May start a download
		ifaces.append(iface)
		for x in p.stale_feeds:
			print "Updating stale feed", feed
			p.begin_iface_download(x)
		if handler.monitored_downloads:
			print "Waiting for downloads for", feed
			try:
				errors = handler.wait_for_downloads()
			except SafeException, ex:
				warn("Error updating '%s': %s", feed, str(ex))
				continue
			for error in errors or []:
				print error

		cached = basedir.load_first_cache(namespaces.config_site, 'interfaces', model.escape(feed))
		if not cached:
			# Error during download?
			warn("Attempted to fetch '%s', but still not cached", feed)
			continue

		style = os.path.join(feed_dir, 'interface.xsl')
		if not os.path.islink(style):
			os.symlink('../../../../feed_style.xsl', style)

		latest = os.path.join(feed_dir, 'latest.xml')

		last_modified = int(os.stat(cached).st_mtime)
		version_name = time.strftime('%Y-%m-%d_%H:%M.xml', time.gmtime(last_modified))
		version_path = os.path.join(feed_dir, version_name)

		if os.path.islink(latest) and os.readlink(latest) == version_name:
			if os.path.exists(version_path):
				continue
			warn("Broken symlink '%s'!", latest)

		# Get the keys
		stream = file(cached)
		unused, sigs = gpg.check_stream(stream)
		stream.close()

		for x in sigs:
			if isinstance(x, gpg.ValidSig):
				ensure_key(x.fingerprint)
			else:
				warn("Signature problem: ", x)

		shutil.copyfile(cached, version_path)
		latest_new = latest + '.new'
		if os.path.exists(latest_new):
			os.unlink(latest_new)
		os.symlink(version_name, latest_new)
		os.rename(latest_new, latest)
		print "Updated %s to %s" % (feed, version_name)

	latest_ifaces = [(iface.last_modified, iface) for iface in ifaces]
	latest_ifaces.sort()
	latest_ifaces = reversed(latest_ifaces[-16:])
	for date, iface in latest_ifaces:
		summary = minidom.parseString(summary_xml)
		set_element(summary, "summary/div/a", iface.get_name())
		set_element(summary, "summary/div/a/@href", iface.uri)
		set_element(summary, "summary/div/span", iface.summary)
		news_feed.add_entry(title = "%s feed updated" % iface.get_name(),
			       link = iface.uri,
			       extra_links = {'http://0install.net/2007/namespaces/0mirror/cached':
			       			site_address + "/" + get_feed_dir(iface.uri).replace('#', '%23') + "/latest.xml"},
			       entry_id = iface.uri,
			       updated = format_date(date),
			       summary = summary.documentElement)
	
	news_stream = file(os.path.join(public_dir, 'news-feed.xml'), 'w')
	news_feed.save(news_stream)
	news_stream.close()

except KeyboardInterrupt, ex:
	print >>sys.stderr, "Aborted at user's request"
	sys.exit(1)
except SafeException, ex:
	if options.verbose: raise
	print >>sys.stderr, ex
	sys.exit(1)
